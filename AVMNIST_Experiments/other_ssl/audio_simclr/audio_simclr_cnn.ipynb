{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSL Method: SimCLR (Audio only) - CNN encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../../\") # Add the parent directory to the path\n",
    "from utils.reproducibility import set_seed\n",
    "set_seed(1)\n",
    "import torch\n",
    "import os\n",
    "from utils.get_data import AVMNISTDataModule, AVMNISTSimCLRDataModule\n",
    "from models.dino import SpectrogramEncoder\n",
    "from training_structures.ssl_train import train_and_evaluate_ssl\n",
    "from audio_simclr import AudioSimCLRLightning\n",
    "current_path = os.getcwd()\n",
    "root_path = \"../../\"\n",
    "data_dir=f'{root_path}/data/avmnist/'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\lightning\\fabric\\connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GFLOPs: 0.36 GFLOPs\n",
      "Model Parameters: 0.65 M parameters\n",
      "Training with seed 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type             | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model | AudioSimCLRModel | 652 K  | train\n",
      "---------------------------------------------------\n",
      "652 K     Trainable params\n",
      "0         Non-trainable params\n",
      "652 K     Total params\n",
      "2.611     Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 215/215 [01:08<00:00,  3.14it/s, v_num=eed1, train_loss_step=0.0154, train_loss_epoch=0.0238]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 215/215 [01:08<00:00,  3.13it/s, v_num=eed1, train_loss_step=0.0154, train_loss_epoch=0.0238]\n",
      "Extracting training features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:15<00:00, 28.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 27.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\../..\\training_structures\\dino_train.py:229: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=True) # For mixed precision training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy (k=5): 23.0500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 430/430 [00:13<00:00, 31.33it/s, loss=1.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.9973, Val Loss: 1.8516, Val Acc: 33.56%\n",
      "Saved best model with validation accuracy: 33.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 430/430 [00:13<00:00, 32.60it/s, loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1.8045, Val Loss: 1.7553, Val Acc: 37.04%\n",
      "Saved best model with validation accuracy: 37.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 430/430 [00:13<00:00, 32.51it/s, loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 1.7348, Val Loss: 1.7243, Val Acc: 38.68%\n",
      "Saved best model with validation accuracy: 38.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 430/430 [00:13<00:00, 32.52it/s, loss=1.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 1.6896, Val Loss: 1.6850, Val Acc: 40.28%\n",
      "Saved best model with validation accuracy: 40.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 430/430 [00:13<00:00, 31.99it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 1.6596, Val Loss: 1.6669, Val Acc: 40.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 430/430 [00:12<00:00, 33.09it/s, loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 1.6370, Val Loss: 1.6580, Val Acc: 40.90%\n",
      "Saved best model with validation accuracy: 40.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 430/430 [00:13<00:00, 31.48it/s, loss=1.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 1.6182, Val Loss: 1.6404, Val Acc: 42.02%\n",
      "Saved best model with validation accuracy: 42.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 430/430 [00:13<00:00, 32.55it/s, loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 1.6059, Val Loss: 1.6315, Val Acc: 41.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 430/430 [00:12<00:00, 33.33it/s, loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 1.5988, Val Loss: 1.6242, Val Acc: 42.36%\n",
      "Saved best model with validation accuracy: 42.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 430/430 [00:13<00:00, 32.41it/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 1.5943, Val Loss: 1.6276, Val Acc: 42.48%\n",
      "Saved best model with validation accuracy: 42.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\../..\\training_structures\\dino_train.py:317: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(save_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 38.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\lightning\\fabric\\connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model | AudioSimCLRModel | 652 K  | train\n",
      "---------------------------------------------------\n",
      "652 K     Trainable params\n",
      "0         Non-trainable params\n",
      "652 K     Total params\n",
      "2.611     Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio KNN Accuracy: 23.05, MLP Accuracy: 38.06\n",
      "Training with seed 2...\n",
      "Epoch 99: 100%|██████████| 215/215 [01:03<00:00,  3.37it/s, v_num=eed2, train_loss_step=0.0193, train_loss_epoch=0.0245]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 215/215 [01:03<00:00,  3.37it/s, v_num=eed2, train_loss_step=0.0193, train_loss_epoch=0.0245]\n",
      "Extracting training features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:18<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\../..\\training_structures\\dino_train.py:229: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=True) # For mixed precision training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy (k=5): 23.0100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 430/430 [00:11<00:00, 35.85it/s, loss=1.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 2.0175, Val Loss: 1.8685, Val Acc: 33.16%\n",
      "Saved best model with validation accuracy: 33.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 430/430 [00:11<00:00, 36.42it/s, loss=1.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1.8225, Val Loss: 1.7816, Val Acc: 36.68%\n",
      "Saved best model with validation accuracy: 36.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 430/430 [00:12<00:00, 33.78it/s, loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 1.7464, Val Loss: 1.7559, Val Acc: 38.06%\n",
      "Saved best model with validation accuracy: 38.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 430/430 [00:12<00:00, 35.38it/s, loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 1.7024, Val Loss: 1.7120, Val Acc: 38.44%\n",
      "Saved best model with validation accuracy: 38.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 430/430 [00:11<00:00, 36.87it/s, loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 1.6720, Val Loss: 1.6863, Val Acc: 40.14%\n",
      "Saved best model with validation accuracy: 40.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 430/430 [00:11<00:00, 35.93it/s, loss=1.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 1.6478, Val Loss: 1.6583, Val Acc: 40.70%\n",
      "Saved best model with validation accuracy: 40.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 430/430 [00:11<00:00, 36.36it/s, loss=1.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 1.6320, Val Loss: 1.6526, Val Acc: 40.92%\n",
      "Saved best model with validation accuracy: 40.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 430/430 [00:11<00:00, 35.85it/s, loss=1.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 1.6187, Val Loss: 1.6455, Val Acc: 41.30%\n",
      "Saved best model with validation accuracy: 41.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 430/430 [00:11<00:00, 36.86it/s, loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 1.6112, Val Loss: 1.6391, Val Acc: 41.68%\n",
      "Saved best model with validation accuracy: 41.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 430/430 [00:12<00:00, 33.62it/s, loss=1.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 1.6071, Val Loss: 1.6394, Val Acc: 41.88%\n",
      "Saved best model with validation accuracy: 41.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\../..\\training_structures\\dino_train.py:317: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(save_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 38.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\lightning\\fabric\\connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type             | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | model | AudioSimCLRModel | 652 K  | train\n",
      "---------------------------------------------------\n",
      "652 K     Trainable params\n",
      "0         Non-trainable params\n",
      "652 K     Total params\n",
      "2.611     Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio KNN Accuracy: 23.01, MLP Accuracy: 38.15\n",
      "Training with seed 3...\n",
      "Epoch 99: 100%|██████████| 215/215 [01:00<00:00,  3.56it/s, v_num=eed3, train_loss_step=0.0243, train_loss_epoch=0.0248]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 215/215 [01:00<00:00,  3.56it/s, v_num=eed3, train_loss_step=0.0243, train_loss_epoch=0.0248]\n",
      "Extracting training features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:13<00:00, 31.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 31.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\../..\\training_structures\\dino_train.py:229: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=True) # For mixed precision training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy (k=5): 22.6500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 430/430 [00:11<00:00, 35.98it/s, loss=1.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 2.0149, Val Loss: 1.8733, Val Acc: 33.78%\n",
      "Saved best model with validation accuracy: 33.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 430/430 [00:11<00:00, 36.50it/s, loss=1.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1.8268, Val Loss: 1.7803, Val Acc: 36.76%\n",
      "Saved best model with validation accuracy: 36.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 430/430 [00:11<00:00, 36.47it/s, loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 1.7545, Val Loss: 1.7235, Val Acc: 38.80%\n",
      "Saved best model with validation accuracy: 38.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 430/430 [00:11<00:00, 36.50it/s, loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 1.7066, Val Loss: 1.7036, Val Acc: 38.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 430/430 [00:11<00:00, 37.20it/s, loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 1.6736, Val Loss: 1.6667, Val Acc: 40.96%\n",
      "Saved best model with validation accuracy: 40.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 430/430 [00:11<00:00, 37.07it/s, loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 1.6506, Val Loss: 1.6512, Val Acc: 41.40%\n",
      "Saved best model with validation accuracy: 41.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 430/430 [00:11<00:00, 37.10it/s, loss=1.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 1.6334, Val Loss: 1.6434, Val Acc: 40.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 430/430 [00:11<00:00, 37.08it/s, loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 1.6201, Val Loss: 1.6345, Val Acc: 41.80%\n",
      "Saved best model with validation accuracy: 41.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 430/430 [00:11<00:00, 37.10it/s, loss=1.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 1.6129, Val Loss: 1.6302, Val Acc: 42.56%\n",
      "Saved best model with validation accuracy: 42.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 430/430 [00:11<00:00, 37.09it/s, loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 1.6080, Val Loss: 1.6295, Val Acc: 42.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\../..\\training_structures\\dino_train.py:317: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(save_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 37.65%\n",
      "Audio KNN Accuracy: 22.650000000000002, MLP Accuracy: 37.65\n",
      "Collecting samples from dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 71.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected digits for visualization: [5, 8]\n",
      "Collecting samples from dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 69.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing digits: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\Desktop\\vub-github\\Thesis-project\\AVMNIST_Experiments\\other_ssl\\audio_simclr\\../..\\utils\\visualisations.py:707: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting samples from dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 46.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing digits: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Applying t-SNE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ward\\anaconda3\\envs\\multibench\\Lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1162: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_data_module = AVMNISTSimCLRDataModule(data_dir=data_dir, batch_size=256, num_workers=6)\n",
    "test_data_module = AVMNISTDataModule(data_dir=data_dir, batch_size=128, num_workers=0)\n",
    "num_epochs = 100\n",
    "model_dir, model_name = f\"{current_path}\", \"audio_simclr_model_cnn\"\n",
    "module = AudioSimCLRLightning(audio_encoder_cls=SpectrogramEncoder, \n",
    "                              projection_dim=128, output_dim=256, learning_rate=0.001, \n",
    "                              num_epochs=num_epochs, use_mixed_precision=True)\n",
    "seeds = [1, 2, 3]\n",
    "input_data = [ # img1, spec1, img2, spec2\n",
    "    (torch.randn(1, 1, 28, 28), # images are unused but model expects a batch of 4 inputs\n",
    "    torch.randn(1, 1, 112, 112),  \n",
    "    torch.randn(1, 1, 28, 28),\n",
    "    torch.randn(1, 1, 112, 112))      \n",
    "]\n",
    "\n",
    "train_and_evaluate_ssl(\n",
    "    module=module,\n",
    "    train_data_module=train_data_module,\n",
    "    test_data_module=test_data_module,\n",
    "    model_dir=model_dir,\n",
    "    model_name=model_name,\n",
    "    input_data=input_data,\n",
    "    modalities=[\"audio\"],\n",
    "    seeds=[1, 2, 3],\n",
    "    num_epochs=num_epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multibench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
